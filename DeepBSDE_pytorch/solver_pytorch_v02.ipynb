{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "solver_pytorch_v02.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wqiu96/summer_project/blob/master/DeepBSDE_pytorch/solver_pytorch_v02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73bJqAeGufsI",
        "colab_type": "code",
        "outputId": "a67510b1-9595-4b75-d8cb-44e05d042a06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "!git clone https://github.com/wqiu96/summer_project.git"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'summer_project'...\n",
            "remote: Enumerating objects: 85, done.\u001b[K\n",
            "remote: Counting objects: 100% (85/85), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 553 (delta 37), reused 0 (delta 0), pack-reused 468\u001b[K\n",
            "Receiving objects: 100% (553/553), 2.52 MiB | 6.82 MiB/s, done.\n",
            "Resolving deltas: 100% (285/285), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVY1CtJ9utse",
        "colab_type": "code",
        "outputId": "417b54d6-e350-4297-e044-1c37a2221139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd summer_project/DeepBSDE_pytorch/"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/summer_project/DeepBSDE_pytorch/summer_project/DeepBSDE_pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vvaZbEWRYSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.distributions import uniform\n",
        "import torchvision\n",
        "from equation_pytorch import get_equation\n",
        "from config_pytorch import get_config\n",
        "\n",
        "\n",
        "MOMENTUM = 0.99\n",
        "EPSILON = 1e-6\n",
        "DELTA_CLIP = 50.0\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,num_hiddens):\n",
        "      super(Net, self).__init__()\n",
        "      self.num_hiddens = num_hiddens\n",
        "      \n",
        "      self.fc1 = nn.Linear(num_hiddens[0], num_hiddens[1], bias=False)\n",
        "      self.norm1 = nn.LayerNorm(num_hiddens[1])\n",
        "      self.fc2 = nn.Linear(num_hiddens[1], num_hiddens[2], bias=False)\n",
        "      self.norm2 = nn.LayerNorm(num_hiddens[2])\n",
        "      self.fc3 = nn.Linear(num_hiddens[2], num_hiddens[3], bias=False)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      # h1 = relu(xw1)\n",
        "      x = self.norm1(F.relu(self.fc1(x)))\n",
        "      # h2 = relu(h1w2)\n",
        "      x = self.norm1(F.relu(self.fc2(x)))\n",
        "      # h3 = h2w3\n",
        "      x = self.fc3(x)\n",
        "      #termin time\n",
        "      return x\n",
        "      \n",
        "\n",
        "class DeepNet(nn.Module):\n",
        "    def __init__(self,num_hiddens,config,bsde):\n",
        "      super(DeepNet, self).__init__()\n",
        "      self.num_hiddens = num_hiddens\n",
        "      self._config = config\n",
        "      self._bsde = bsde\n",
        "      \n",
        "      # make sure consistent with FBSDE equation\n",
        "      self._dim = bsde.dim\n",
        "      self._num_time_interval = bsde.num_time_interval\n",
        "      # ops for statistics update of batch normalization\n",
        "      self.linears = nn.ModuleList([Net(num_hiddens) for i in range(bsde.num_time_interval - 1)])\n",
        "    \n",
        "    def forward(self,x):\n",
        "      #dw_train= torch.from_numpy(self._bsde.sample()[0])\n",
        "      dw_train= self._bsde.sample()[0].astype(np.float32)\n",
        "      time_stamp = np.arange(0, self._bsde.num_time_interval) * self._bsde.delta_t\n",
        "      m = uniform.Uniform(self._config.y_init_range[0],self._config.y_init_range[1])\n",
        "      y = Variable(m.sample()) #initial\n",
        "      z = 2*torch.rand([self._dim,1],dtype=torch.float32) - 1 #same as the original\n",
        "      for t in range(0,bsde.num_time_interval - 1):\n",
        "        dw = torch.from_numpy(dw_train[:, t]).view(1,100)\n",
        "        torch.mm(dw.float(), z.float()) # torch.mm have bug use x.float()\n",
        "        y = y - self._bsde.delta_t* (self._bsde.f_tf(time_stamp[t], x[:, t], y, z)) + torch.mm(dw, z)\n",
        "        z = (self.linears[t](x[:,t]) / self._dim).view(100,1)\n",
        "      #terminal condition\n",
        "      dw = torch.from_numpy(dw_train[:, -1]).view(1,100)\n",
        "      y = y - self._bsde.delta_t * (self._bsde.f_tf(time_stamp[-1], x[:, -2], y, z)) + torch.mm(dw, z)\n",
        "      return y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsW-av2BdFQZ",
        "colab_type": "code",
        "outputId": "0a6f0412-12db-4b17-9a28-e654415a3ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "config = get_config('HJB')\n",
        "bsde = get_equation('HJB', config.dim, config.total_time, config.num_time_interval)\n",
        "\n",
        "deepNet = DeepNet(config.num_hiddens,config,bsde)\n",
        "optimizer = optim.SGD(deepNet.parameters(), lr=0.001, momentum=MOMENTUM) # lr have some different wiht the original\n",
        "train_loss = []\n",
        "for epoch in range(config.num_iterations):\n",
        "  x_ = bsde.sample()[1].astype(np.float32)\n",
        "  x = torch.from_numpy(x_)\n",
        "  out = deepNet(x)\n",
        "  delta = out - bsde.g_tf(bsde.total_time, x[:, -1])\n",
        "  loss = torch.mean(torch.where(torch.abs(delta) < DELTA_CLIP, torch.pow(delta,2),2 * DELTA_CLIP * torch.abs(delta) - DELTA_CLIP ** 2))\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  train_loss.append(loss.item())\n",
        "  if epoch % 100 == 0 :\n",
        "    print(epoch, loss.item(), out)\n",
        "  if loss <= 0.001:\n",
        "    print(epoch, loss.item(), out)\n",
        "    break\n",
        "    "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 5.093466758728027 tensor([[2.1736]], grad_fn=<AddBackward0>)\n",
            "100 11.287697792053223 tensor([[1.5246]], grad_fn=<AddBackward0>)\n",
            "200 8.326814651489258 tensor([[1.7512]], grad_fn=<AddBackward0>)\n",
            "300 5.676868438720703 tensor([[2.2280]], grad_fn=<AddBackward0>)\n",
            "316 0.00021527578064706177 tensor([[4.6147]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}