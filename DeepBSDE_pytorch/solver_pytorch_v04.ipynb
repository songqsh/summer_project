{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "solver_pytorch_v04.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wqiu96/summer_project/blob/master/DeepBSDE_pytorch/solver_pytorch_v04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73bJqAeGufsI",
        "colab_type": "code",
        "outputId": "7b63f408-bbc8-44d8-d9b3-4fee2f1a11de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "!git clone https://github.com/wqiu96/summer_project.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'summer_project'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (17/17), done.\u001b[K\n",
            "remote: Total 654 (delta 5), reused 0 (delta 0), pack-reused 637\u001b[K\n",
            "Receiving objects: 100% (654/654), 2.54 MiB | 6.64 MiB/s, done.\n",
            "Resolving deltas: 100% (332/332), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVY1CtJ9utse",
        "colab_type": "code",
        "outputId": "135654fa-a132-450e-ee1a-f19db982a24a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd summer_project/DeepBSDE_pytorch/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/summer_project/DeepBSDE_pytorch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vvaZbEWRYSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.distributions import uniform\n",
        "import torchvision\n",
        "from equation_pytorch import get_equation\n",
        "from config_pytorch import get_config\n",
        "\n",
        "\n",
        "MOMENTUM = 0.99\n",
        "EPSILON = 1e-6\n",
        "DELTA_CLIP = 50.0\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,num_hiddens):\n",
        "      super(Net, self).__init__()\n",
        "      self.num_hiddens = num_hiddens\n",
        "      \n",
        "      self.fc1 = nn.Linear(num_hiddens[0], num_hiddens[1], bias=False)\n",
        "      self.norm1 = nn.LayerNorm(num_hiddens[1])\n",
        "      self.fc2 = nn.Linear(num_hiddens[1], num_hiddens[2], bias=False)\n",
        "      self.norm2 = nn.LayerNorm(num_hiddens[2])\n",
        "      self.fc3 = nn.Linear(num_hiddens[2], num_hiddens[3], bias=False)\n",
        "    \n",
        "    def forward(self, x):\n",
        "      # h1 = relu(xw1)\n",
        "      x = self.norm1(F.relu(self.fc1(x)))\n",
        "      #x = self.norm1(self.fc1(x))\n",
        "      # h2 = relu(h1w2)\n",
        "      #x = self.norm2(self.fc2(x))\n",
        "      x = self.norm1(F.relu(self.fc2(x)))\n",
        "      # h3 = h2w3\n",
        "      x = self.fc3(x)\n",
        "      #termin time\n",
        "      return x\n",
        "      \n",
        "\n",
        "class DeepNet(nn.Module):\n",
        "    def __init__(self,num_hiddens,config,bsde):\n",
        "      super(DeepNet, self).__init__()\n",
        "      self.num_hiddens = num_hiddens\n",
        "      self._config = config\n",
        "      self._bsde = bsde\n",
        "      self.y_init = 0\n",
        "      self._dim = bsde.dim\n",
        "      self._num_time_interval = bsde.num_time_interval\n",
        "      self.linears = nn.ModuleList([Net(num_hiddens) for i in range(bsde.num_time_interval - 1)])\n",
        "      m = uniform.Uniform(config.y_init_range[0],config.y_init_range[1])\n",
        "      self.y_init = torch.nn.Parameter(m.sample())\n",
        "      self.z_init = torch.nn.Parameter(2*torch.rand([self._dim,1],dtype=torch.float32) - 1)\n",
        "\n",
        "    \n",
        "    def forward(self,x):\n",
        "      dw_train= self._bsde.sample()[0].astype(np.float32)\n",
        "      time_stamp = np.arange(0, self._bsde.num_time_interval) * self._bsde.delta_t\n",
        "      z = self.z_init\n",
        "      y_ = self.y_init\n",
        "      for t in range(0,bsde.num_time_interval - 1):\n",
        "        dw = torch.from_numpy(dw_train[:, t]).view(1,self._dim)\n",
        "        torch.mm(dw.float(), z.float()) # torch.mm have bug use x.float()\n",
        "        y_ = y_ - self._bsde.delta_t* (self._bsde.f_tf(time_stamp[t], x[:, t], y_, z)) + torch.mm(dw, z)\n",
        "        z = (self.linears[t](x[:,t]) / self._dim).view(self._dim,1)\n",
        "      #terminal condition\n",
        "      dw = torch.from_numpy(dw_train[:, -1]).view(1,self._dim)\n",
        "      y_ = y_ - self._bsde.delta_t * (self._bsde.f_tf(time_stamp[-1], x[:, -2], y_, z)) + torch.mm(dw, z)\n",
        "      return y_\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T2dlXoInZEV",
        "colab_type": "text"
      },
      "source": [
        "Result:\n",
        "- AllenCahn: sometimes my code can give the similar result as the original code, sometimes the result is nan(because the loss is too small to learn??).\n",
        "- HJB: sometimes have the same result as paper,sometimes not\n",
        "- PricingOption: about 21\n",
        "- PricingDefaultRisk: about 56\n",
        "- BurgesType: about 1.2\n",
        "- QuadraticGradients: about 2.55 but the paper's result is 0.8\n",
        "- ReactionDiffusion : Multiple results compared with the paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsW-av2BdFQZ",
        "colab_type": "code",
        "outputId": "988bbd0f-6f73-452b-9189-5acf31012b4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "config = get_config('HJB')\n",
        "bsde = get_equation('HJB', config.dim, config.total_time, config.num_time_interval)\n",
        "\n",
        "deepNet = DeepNet(config.num_hiddens,config,bsde)\n",
        "optimizer = optim.SGD(deepNet.parameters(), lr=0.00001, momentum=MOMENTUM) # lr have some different wiht the original\n",
        "#torch.optim.lr_scheduler.MultiStepLR(optimizer, [15,25,35], gamma=0.1, last_epoch=-1) # Adjust learning rate according to time\n",
        "train_loss = []\n",
        "for epoch in range(10000):\n",
        "  x_ = bsde.sample()[1].astype(np.float32)\n",
        "  x = torch.from_numpy(x_)\n",
        "  out = deepNet(x)\n",
        "  delta = out - bsde.g_tf(bsde.total_time, x[:, -1])\n",
        "  #loss = torch.mean(torch.where(torch.abs(delta) < DELTA_CLIP, torch.pow(delta,2),2 * DELTA_CLIP * torch.abs(delta) - DELTA_CLIP ** 2))\n",
        "  loss = delta**2\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  train_loss.append(loss.item())\n",
        "  if epoch % 100 == 0 :\n",
        "    print(epoch, loss.item(), deepNet.y_init)\n",
        "  if 100*loss <= 0.0001:\n",
        "    print(epoch, loss.item(), deepNet.y_init)\n",
        "    break\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.7937805652618408 Parameter containing:\n",
            "tensor(0.4721, requires_grad=True)\n",
            "100 10.391447067260742 Parameter containing:\n",
            "tensor(0.5115, requires_grad=True)\n",
            "200 7.30047082901001 Parameter containing:\n",
            "tensor(0.5988, requires_grad=True)\n",
            "300 4.400335788726807 Parameter containing:\n",
            "tensor(0.6742, requires_grad=True)\n",
            "400 0.15143370628356934 Parameter containing:\n",
            "tensor(0.7115, requires_grad=True)\n",
            "500 0.11232168972492218 Parameter containing:\n",
            "tensor(0.7429, requires_grad=True)\n",
            "600 0.02014237828552723 Parameter containing:\n",
            "tensor(0.7845, requires_grad=True)\n",
            "700 0.3120235800743103 Parameter containing:\n",
            "tensor(0.8578, requires_grad=True)\n",
            "800 1.472190022468567 Parameter containing:\n",
            "tensor(0.9153, requires_grad=True)\n",
            "900 1.7003600597381592 Parameter containing:\n",
            "tensor(0.9323, requires_grad=True)\n",
            "1000 0.4393395781517029 Parameter containing:\n",
            "tensor(0.9377, requires_grad=True)\n",
            "1100 0.05825768783688545 Parameter containing:\n",
            "tensor(0.9497, requires_grad=True)\n",
            "1187 6.449904503824655e-07 Parameter containing:\n",
            "tensor(0.9559, requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}