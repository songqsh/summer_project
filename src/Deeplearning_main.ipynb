{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deeplearning_main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wqiu96/summer_project/blob/master/src/Deeplearning_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "RWs5BXceNNt9",
        "colab_type": "code",
        "outputId": "f2ee4357-e104-4755-8f18-18cfeed4f262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/frankhan91/DeepBSDE.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'DeepBSDE'...\n",
            "remote: Enumerating objects: 20, done.\u001b[K\n",
            "remote: Total 20 (delta 0), reused 0 (delta 0), pack-reused 20\u001b[K\n",
            "Unpacking objects: 100% (20/20), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wpK0LRyepDOX",
        "colab_type": "code",
        "outputId": "e2c1547d-ff5b-4d5a-8f57-859765f724a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "cd DeepBSDE/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/DeepBSDE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y34BsXPdpDin",
        "colab_type": "code",
        "outputId": "a50f90b6-316b-46b0-8d2a-05fc463b0638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "import logging\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from config import get_config\n",
        "from equation import get_equation\n",
        "from solver import FeedForwardModel\n",
        "\n",
        "FLAGS = tf.app.flags.FLAGS\n",
        "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
        "tf.app.flags.DEFINE_string('problem_name', 'HJB',\n",
        "                           \"\"\"The name of partial differential equation.\"\"\")\n",
        "tf.app.flags.DEFINE_integer('num_run', 1,\n",
        "                            \"\"\"The number of experiments to repeatedly run for the same problem.\"\"\")\n",
        "tf.app.flags.DEFINE_string('log_dir', './logs',\n",
        "                           \"\"\"Directory where to write event logs and output array.\"\"\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    problem_name = FLAGS.problem_name\n",
        "    config = get_config(problem_name)\n",
        "    bsde = get_equation(problem_name, config.dim, config.total_time, config.num_time_interval)\n",
        "\n",
        "    if not os.path.exists(FLAGS.log_dir):\n",
        "        os.mkdir(FLAGS.log_dir)\n",
        "    path_prefix = os.path.join(FLAGS.log_dir, problem_name)\n",
        "    with open('{}_config.json'.format(path_prefix), 'w') as outfile:\n",
        "        json.dump(dict((name, getattr(config, name))\n",
        "                       for name in dir(config) if not name.startswith('__')),\n",
        "                  outfile, indent=2)\n",
        "    logging.basicConfig(level=logging.INFO,\n",
        "                        format='%(levelname)-6s %(message)s')\n",
        "\n",
        "    for idx_run in range(1, FLAGS.num_run+1):\n",
        "        tf.reset_default_graph()\n",
        "        with tf.Session() as sess:\n",
        "            logging.info('Begin to solve %s with run %d' % (problem_name, idx_run))\n",
        "            model = FeedForwardModel(config, bsde, sess)\n",
        "            if bsde.y_init:\n",
        "                logging.info('Y0_true: %.4e' % bsde.y_init)\n",
        "            model.build()\n",
        "            training_history = model.train()\n",
        "            if bsde.y_init:\n",
        "                logging.info('relative error of Y0: %s',\n",
        "                             '{:.2%}'.format(\n",
        "                                 abs(bsde.y_init - training_history[-1, 2])/bsde.y_init))\n",
        "            # save training history\n",
        "            np.savetxt('{}_training_history_{}.csv'.format(path_prefix, idx_run),\n",
        "                       training_history,\n",
        "                       fmt=['%d', '%.5e', '%.5e', '%d'],\n",
        "                       delimiter=\",\",\n",
        "                       header=\"step,loss_function,target_value,elapsed_time\",\n",
        "                       comments='')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO   Begin to solve HJB with run 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From equation.py:98: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING From equation.py:98: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO   step:     0,    loss: 1.9327e+01,   Y0: 1.9596e-01,  elapsed time  23\n",
            "INFO   step:   100,    loss: 5.7515e+00,   Y0: 1.1026e+00,  elapsed time  39\n",
            "INFO   step:   200,    loss: 2.7857e+00,   Y0: 1.4134e+00,  elapsed time  46\n",
            "INFO   step:   300,    loss: 2.5864e+00,   Y0: 1.6258e+00,  elapsed time  53\n",
            "INFO   step:   400,    loss: 2.3271e+00,   Y0: 1.8679e+00,  elapsed time  60\n",
            "INFO   step:   500,    loss: 2.0594e+00,   Y0: 2.1397e+00,  elapsed time  67\n",
            "INFO   step:   600,    loss: 1.8110e+00,   Y0: 2.4377e+00,  elapsed time  74\n",
            "INFO   step:   700,    loss: 1.5003e+00,   Y0: 2.7700e+00,  elapsed time  81\n",
            "INFO   step:   800,    loss: 1.2043e+00,   Y0: 3.1083e+00,  elapsed time  88\n",
            "INFO   step:   900,    loss: 8.5866e-01,   Y0: 3.4630e+00,  elapsed time  95\n",
            "INFO   step:  1000,    loss: 5.3533e-01,   Y0: 3.8173e+00,  elapsed time 102\n",
            "INFO   step:  1100,    loss: 2.8359e-01,   Y0: 4.1219e+00,  elapsed time 109\n",
            "INFO   step:  1200,    loss: 1.1090e-01,   Y0: 4.3729e+00,  elapsed time 116\n",
            "INFO   step:  1300,    loss: 3.8662e-02,   Y0: 4.5144e+00,  elapsed time 123\n",
            "INFO   step:  1400,    loss: 2.5875e-02,   Y0: 4.5746e+00,  elapsed time 130\n",
            "INFO   step:  1500,    loss: 2.4150e-02,   Y0: 4.5941e+00,  elapsed time 137\n",
            "INFO   step:  1600,    loss: 2.4336e-02,   Y0: 4.5996e+00,  elapsed time 143\n",
            "INFO   step:  1700,    loss: 2.4134e-02,   Y0: 4.6016e+00,  elapsed time 151\n",
            "INFO   step:  1800,    loss: 2.4201e-02,   Y0: 4.5986e+00,  elapsed time 158\n",
            "INFO   step:  1900,    loss: 2.3842e-02,   Y0: 4.5985e+00,  elapsed time 165\n",
            "INFO   step:  2000,    loss: 2.3923e-02,   Y0: 4.5977e+00,  elapsed time 172\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}